{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Pose Estimation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"73J-hQSSBZoN"},"source":["# Generating Point Clouds from ModelNet10"]},{"cell_type":"code","metadata":{"id":"1nLaqEsDfcqj"},"source":["import numpy as np\n","import random\n","import math\n","!pip install path.py;\n","from path import Path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"orz1z-1Ffmay"},"source":["!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n","!unzip -q ModelNet10.zip\n","\n","path = Path(\"ModelNet10\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HJzHZglpfw5y"},"source":["def read_off(file):\n","    if 'OFF' != file.readline().strip():\n","        raise('Not a valid OFF header')\n","    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n","    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n","    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n","    return verts, faces\n","\n","with open(path/\"toilet/train/toilet_0002.off\", 'r') as f:\n","    mesh = read_off(f)\n","\n","verts, faces = mesh\n","areas = np.zeros((len(faces)))\n","verts = np.array(verts)\n","\n","# function to calculate triangle area by its vertices\n","# https://en.wikipedia.org/wiki/Heron%27s_formula\n","def triangle_area(pt1, pt2, pt3):\n","    side_a = np.linalg.norm(pt1 - pt2)\n","    side_b = np.linalg.norm(pt2 - pt3)\n","    side_c = np.linalg.norm(pt3 - pt1)\n","    s = 0.5 * ( side_a + side_b + side_c)\n","    return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n","\n","# we calculate areas of all faces in our mesh\n","for i in range(len(areas)):\n","    areas[i] = (triangle_area(verts[faces[i][0]],\n","                              verts[faces[i][1]],\n","                              verts[faces[i][2]]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DUuOL4Aah6cO"},"source":["import matplotlib.pyplot as plt\n","\n","fig = plt.figure(figsize=(12,8), dpi= 100)\n","ax = plt.axes(projection='3d')\n","\n","#for i in range(0, int(len(verts)/3)):\n","ax.scatter3D(verts[:,0], verts[:,1], verts[:,2], c=verts[:,2], cmap='rainbow');\n","\n","plt.figure()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"csJDcnilkdqS"},"source":["k = 3000\n","# we sample 'k' faces with probabilities proportional to their areas\n","# weights are used to create a distribution.\n","# they don't have to sum up to one.\n","sampled_faces = (random.choices(faces, \n","                                weights=areas,\n","                                k=k))\n","\n","# function to sample points on a triangle surface\n","def sample_point(pt1, pt2, pt3):\n","    # barycentric coordinates on a triangle\n","    # https://mathworld.wolfram.com/BarycentricCoordinates.html\n","    s, t = sorted([random.random(), random.random()])\n","    f = lambda i: s * pt1[i] + (t-s) * pt2[i] + (1-t) * pt3[i]\n","    return (f(0), f(1), f(2))\n"," \n","pointcloud = np.zeros((k, 3))\n","\n","# sample points on chosen faces for the point cloud of size 'k'\n","for i in range(len(sampled_faces)):\n","    pointcloud[i] = (sample_point(verts[sampled_faces[i][0]],\n","                                  verts[sampled_faces[i][1]],\n","                                  verts[sampled_faces[i][2]]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"teK6MqPRkkNs"},"source":["fig = plt.figure(figsize=(8,12), dpi= 100)\n","ax = plt.axes(projection='3d')\n","\n","#for i in range(0, int(len(verts)/3)):\n","ax.scatter3D(pointcloud[:,0], pointcloud[:,1], pointcloud[:,2], c=pointcloud[:,2], cmap='rainbow');\n","\n","plt.figure()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ofsFy9MYf9th"},"source":["# normalize\n","norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n","norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n","noisy_pointcloud = norm_pointcloud\n","'''\n","# rotation around z-axis\n","theta = random.random() * 2. * math.pi # rotation angle\n","rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n","                       [ math.sin(theta),  math.cos(theta),    0],\n","                       [0,                             0,      1]])\n","\n","rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n","\n","# add some noise\n","noise = np.random.normal(0, 0.02, (pointcloud.shape))\n","noisy_pointcloud = rot_pointcloud + noise\n","\n","'''\n","fig = plt.figure(figsize=(8,12), dpi= 100)\n","ax = plt.axes(projection='3d')\n","\n","#for i in range(0, int(len(verts)/3)):\n","ax.scatter3D(noisy_pointcloud[:,0], noisy_pointcloud[:,1], noisy_pointcloud[:,2], c=noisy_pointcloud[:,2], cmap='rainbow');\n","\n","plt.figure()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7W7RiZcWnMul"},"source":["from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import os\n","\n","class PointSampler(object):\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, int)\n","        self.output_size = output_size\n","    \n","    def triangle_area(self, pt1, pt2, pt3):\n","        side_a = np.linalg.norm(pt1 - pt2)\n","        side_b = np.linalg.norm(pt2 - pt3)\n","        side_c = np.linalg.norm(pt3 - pt1)\n","        s = 0.5 * ( side_a + side_b + side_c)\n","        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n","\n","    def sample_point(self, pt1, pt2, pt3):\n","        # barycentric coordinates on a triangle\n","        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n","        s, t = sorted([random.random(), random.random()])\n","        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n","        return (f(0), f(1), f(2))\n","        \n","    \n","    def __call__(self, mesh):\n","        verts, faces = mesh\n","        verts = np.array(verts)\n","        areas = np.zeros((len(faces)))\n","\n","        for i in range(len(areas)):\n","            areas[i] = (self.triangle_area(verts[faces[i][0]],\n","                                           verts[faces[i][1]],\n","                                           verts[faces[i][2]]))\n","            \n","        sampled_faces = (random.choices(faces, \n","                                      weights=areas,\n","                                      cum_weights=None,\n","                                      k=self.output_size))\n","        \n","        sampled_points = np.zeros((self.output_size, 3))\n","\n","        for i in range(len(sampled_faces)):\n","            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n","                                                   verts[sampled_faces[i][1]],\n","                                                   verts[sampled_faces[i][2]]))\n","        \n","        return sampled_points\n","\n","class Normalize(object):\n","    def __call__(self, pointcloud):\n","        assert len(pointcloud.shape)==2\n","        \n","        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n","        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n","\n","        return  norm_pointcloud\n","\n","def default_transforms():\n","    return transforms.Compose([\n","                                PointSampler(1024),\n","                                Normalize(),\n","                                #ToTensor()\n","                              ])\n","    \n","\n","class PointCloudData(Dataset):\n","    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n","        self.root_dir = root_dir\n","        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n","        self.classes = {folder: i for i, folder in enumerate(folders)}\n","        self.transforms = transform if not valid else default_transforms()\n","        self.valid = valid\n","        self.files = []\n","        for category in self.classes.keys():\n","            new_dir = root_dir/Path(category)/folder\n","            for file in os.listdir(new_dir):\n","                if file.endswith('.off'):\n","                    sample = {}\n","                    sample['pcd_path'] = new_dir/file\n","                    sample['category'] = category\n","                    self.files.append(sample)\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __preproc__(self, file):\n","        verts, faces = read_off(file)\n","        if self.transforms:\n","            pointcloud = self.transforms((verts, faces))\n","        return pointcloud\n","\n","    def __getitem__(self, idx):\n","        pcd_path = self.files[idx]['pcd_path']\n","        category = self.files[idx]['category']\n","        with open(pcd_path, 'r') as f:\n","            pointcloud = self.__preproc__(f)\n","        return {'pointcloud': pointcloud, \n","                'category': self.classes[category]}\n","\n","\n","train_transforms = transforms.Compose([\n","                    PointSampler(1024),\n","                    Normalize()\n","                    ])\n","\n","train_ds = PointCloudData(path, transform=train_transforms)\n","valid_ds = PointCloudData(path, valid=True, folder='test', transform=train_transforms)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NzXEj1Fc8UF9"},"source":["#SAMPLING BUT FOR THE AIRPLANE POINT CLOUDS ONLY.\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","path = Path('/content/drive/MyDrive/AIRPLANE/')\n","\n","class PointSampler(object):\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, int)\n","        self.output_size = output_size\n","    \n","    def triangle_area(self, pt1, pt2, pt3):\n","        side_a = np.linalg.norm(pt1 - pt2)\n","        side_b = np.linalg.norm(pt2 - pt3)\n","        side_c = np.linalg.norm(pt3 - pt1)\n","        s = 0.5 * ( side_a + side_b + side_c)\n","        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n","\n","    def sample_point(self, pt1, pt2, pt3):\n","        # barycentric coordinates on a triangle\n","        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n","        s, t = sorted([random.random(), random.random()])\n","        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n","        return (f(0), f(1), f(2))\n","        \n","    \n","    def __call__(self, mesh):\n","        verts, faces = mesh\n","        verts = np.array(verts)\n","        areas = np.zeros((len(faces)))\n","\n","        for i in range(len(areas)):\n","            areas[i] = (self.triangle_area(verts[faces[i][0]],\n","                                           verts[faces[i][1]],\n","                                           verts[faces[i][2]]))\n","            \n","        sampled_faces = (random.choices(faces, \n","                                      weights=areas,\n","                                      cum_weights=None,\n","                                      k=self.output_size))\n","        \n","        sampled_points = np.zeros((self.output_size, 3))\n","\n","        for i in range(len(sampled_faces)):\n","            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n","                                                   verts[sampled_faces[i][1]],\n","                                                   verts[sampled_faces[i][2]]))\n","        \n","        return sampled_points\n","\n","class Normalize(object):\n","    def __call__(self, pointcloud):\n","        assert len(pointcloud.shape)==2\n","        \n","        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n","        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n","\n","        return  norm_pointcloud\n","\n","def default_transforms():\n","    return transforms.Compose([\n","                                PointSampler(3000),\n","                                Normalize(),\n","                                #ToTensor()\n","                              ])\n","    \n","\n","class PointCloudData(Dataset):\n","    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n","        self.root_dir = root_dir\n","        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n","        self.classes = {folder: i for i, folder in enumerate(folders)}\n","        self.transforms = transform if not valid else default_transforms()\n","        self.valid = valid\n","        self.files = []\n","        for category in self.classes.keys():\n","            new_dir = root_dir/Path(category)/folder\n","            for file in os.listdir(new_dir):\n","                if file.endswith('.off'):\n","                    sample = {}\n","                    sample['pcd_path'] = new_dir/file\n","                    sample['category'] = category\n","                    self.files.append(sample)\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __preproc__(self, file):\n","        verts, faces = read_off(file)\n","        if self.transforms:\n","            pointcloud = self.transforms((verts, faces))\n","        return pointcloud\n","\n","    def __getitem__(self, idx):\n","        pcd_path = self.files[idx]['pcd_path']\n","        category = self.files[idx]['category']\n","        with open(pcd_path, 'r') as f:\n","            pointcloud = self.__preproc__(f)\n","        return {'pointcloud': pointcloud, \n","                'category': self.classes[category]}\n","\n","\n","train_transforms = transforms.Compose([\n","                    PointSampler(3000),\n","                    Normalize()\n","                    ])\n","\n","train_ds = PointCloudData(path, transform=train_transforms)\n","valid_ds = PointCloudData(path, valid=True, folder='test', transform=train_transforms)\n","\n","#print(train_ds[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVyI_vGgo6ul"},"source":["train_PC = []\n","test_PC = []\n","for i in range(0, len(train_ds)):\n","    train_PC = np.append(train_PC, train_ds[i]['pointcloud'])\n","    print(i, '/', len(train_ds))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4TFT_iFBqIL"},"source":["test_PC = []\n","for i in range(0, len(valid_ds)):\n","    test_PC = np.append(test_PC, valid_ds[i]['pointcloud'])\n","    print(i, '/', len(valid_ds))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AYDdV5ps5_CZ"},"source":["size = 3000\n","\n","print(np.shape(train_PC))\n","train_PC = np.reshape(train_PC, [626, size, 3])\n","np.shape(train_PC)\n","\n","test_PC = np.reshape(test_PC, [100, size, 3])\n","np.shape(test_PC)\n","\n","print(np.shape(train_PC))\n","print(np.shape(test_PC))\n","\n","np.save('train_point_cloud.npy', train_PC)\n","np.save('test_point_cloud.npy', test_PC)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rhvkQFfyDmS-"},"source":["# Generating Rotated Point Clouds\n"]},{"cell_type":"code","metadata":{"id":"Qo2OXkSYfm9-"},"source":["!pip install git+https://github.com/pygae/clifford.git@master\n","!pip install tensorflow_graphics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B2KnkQyPVGDS"},"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pQBBjP6fq5i"},"source":["from scipy.spatial.transform import Rotation as R\n","import numpy as np\n","from clifford.g3c import *\n","from clifford.tools.g3c import *\n","from clifford.tools.g3c.rotor_parameterisation import *\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","import keras\n","from math import e, pi\n","import random\n","import numpy as np\n","\n","size = 3000\n","\n","P_r_train = np.load('train_point_cloud.npy')\n","P_r_test = np.load('test_point_cloud.npy')\n","\n","\n","P_t_train = np.empty([int(np.shape(P_r_train)[0]), size, 3])\n","P_t_test = np.empty([int(np.shape(P_r_test)[0]), size, 3])\n","\n","tot = int(np.shape(P_r_test)[0] + np.shape(P_r_train)[0])\n","print(tot)\n","b = []\n","r = []\n","\n","len_tr = 626\n","len_te = 100\n","\n","import random\n","\n","for i in range(0,len_tr +len_te):\n","\n","    numero = int(random.uniform(0, 100))\n","    Q = R.random(random_state = numero).as_quat()\n","    Rot = Q[0] + Q[2]*e13 +Q[1]*e23 + Q[3]*e12\n","    B = (1 - Rot)/(1+Rot)\n","    b = np.append(b, [B[6], B[7], B[10]])\n","    r = np.append(r, [Q[0], Q[2], Q[1], Q[3]])\n","    \n","    \n","    if i < int(len_tr):\n","        print(i, \"/\", len_tr)\n","        for j in range(0,size):\n","            P = P_r_train[i,j,0]*e1 + P_r_train[i,j,1]*e2 + P_r_train[i,j,2]*e3\n","            P_prime = Rot*P*~Rot\n","            \n","            P_t_train[i,j,0] = P_prime[1]\n","            P_t_train[i,j,1] = P_prime[2]\n","            P_t_train[i,j,2] = P_prime[3]\n","    \n","    if i > int(len_tr):\n","        print(i-len_tr, \"/\", len_te)\n","        for j in range(0,size):\n","            P = P_r_test[i-len_tr ,j,0]*e1 + P_r_test[i-len_tr ,j,1]*e2 + P_r_test[i-len_tr ,j,2]*e3\n","            P_prime = Rot*P*~Rot\n","\n","            P_t_test[i-len_tr ,j,0] = P_prime[1]\n","            P_t_test[i-len_tr ,j,1] = P_prime[2]\n","            P_t_test[i-len_tr ,j,2] = P_prime[3]\n","\n","\n","\n","P_t_train = np.reshape(P_t_train, [int(np.shape(P_r_train)[0]), size, 3])\n","P_t_test = np.reshape(P_t_test, [int(np.shape(P_r_test)[0]), size, 3])\n","\n","np.save('rotated_train_point_cloud.npy', P_t_train)\n","np.save('rotated_test_point_cloud.npy', P_t_test)\n","np.save('bivector_point_cloud.npy', b)\n","np.save('rotor_point_cloud.npy', r)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XjpBFZDbibRZ"},"source":["from scipy.spatial.transform import Rotation as R\n","import numpy as np\n","from tensorflow.keras.layers import BatchNormalization, MaxPooling1D, Input, Dense, Concatenate\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","from math import acos\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","import keras\n","from math import e, pi\n","import random\n","import numpy as np\n","\n","\n","size = 3000\n","\n","#6D ROTATION!!!!!\n","\n","P_r_train = np.load('train_point_cloud.npy')\n","P_r_test = np.load('test_point_cloud.npy')\n","\n","\n","P_t_train = np.empty([int(np.shape(P_r_train)[0]), size, 3])\n","P_t_test = np.empty([int(np.shape(P_r_test)[0]), size, 3])\n","\n","tot = int(np.shape(P_r_test)[0] + np.shape(P_r_train)[0])\n","print(tot)\n","\n","n = []\n","m = []\n","len_tr = 626\n","len_te = 100\n","\n","import random\n","\n","for i in range(0,len_tr +len_te):\n","\n","    numero = int(random.uniform(0, 100))\n","    r = R.random(random_state = numero).as_matrix()\n","\n","    a1 = r[:,0]\n","    a2 = r[:,1]\n","\n","    b1 = a1 / np.linalg.norm(a1)\n","    b2 = a2 - np.dot(a2,b1)*b1\n","    b2 = b2 / np.linalg.norm(b2)\n","\n","    b3 = np.cross(b1, b2)\n","\n","    print([b1, b2, b3])\n","    print(r)\n","    print('---')\n","    n = np.append(n, np.transpose([b1, b2, b3]))\n","    m = np.append(m, r)\n","    \n","    \n","    if i < int(len_tr):\n","        #print(i, \"/\", len_tr)\n","        for j in range(0,size):\n","            P_prime = np.matmul(r, P_r_train[i,j,:])\n","            \n","            P_t_train[i,j,0] = P_prime[0]\n","            P_t_train[i,j,1] = P_prime[1]\n","            P_t_train[i,j,2] = P_prime[2]\n","    \n","    if i > int(len_tr):\n","        #print(i-len_tr, \"/\", len_te)\n","        for j in range(0,size):\n","            P_prime = np.matmul(r, P_r_test[i-len_tr,j,:])\n","\n","            P_t_test[i-len_tr ,j,0] = P_prime[0]\n","            P_t_test[i-len_tr ,j,1] = P_prime[1]\n","            P_t_test[i-len_tr ,j,2] = P_prime[2]\n","\n","\n","\n","P_t_train = np.reshape(P_t_train, [int(np.shape(P_r_train)[0]), size, 3])\n","P_t_test = np.reshape(P_t_test, [int(np.shape(P_r_test)[0]), size, 3])\n","\n","np.save('6D_rotated_train_point_cloud.npy', P_t_train)\n","np.save('6D_rotated_test_point_cloud.npy', P_t_test)\n","np.save('6D_point_cloud.npy', n)\n","np.save('rotmatr_point_cloud.npy', m)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BAevoNlztI7a"},"source":["# Siamese Network\n","\n"]},{"cell_type":"code","metadata":{"id":"QjKY3y37OzTP"},"source":["!pip install git+https://github.com/pygae/clifford.git@master\n","!pip install tensorflow_graphics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GYcPTiJBO03M"},"source":["from scipy.spatial.transform import Rotation as R\n","import numpy as np\n","from clifford.g3c import *\n","from clifford.tools.g3c import *\n","from clifford.tools.g3c.rotor_parameterisation import *\n","from keras.layers import BatchNormalization, Lambda, Flatten, Dropout, Conv1D, Concatenate\n","from keras.layers import Conv2D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPool1D, GlobalMaxPool2D, MaxPooling2D, Input, Dense, concatenate\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","from math import acos, sqrt\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","import keras\n","from math import e, pi\n","import tensorflow_graphics as tfg\n","import tensorflow_graphics.geometry.transformation as tfg_transformation\n","from sklearn.utils import shuffle\n","from keras.utils.vis_utils import plot_model\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bk7d5A8LLdKH"},"source":["#loading train/test original point cloud and train/test rotated point cloud\n","P_r_train = np.load('train_point_cloud.npy')\n","P_r_test = np.load('test_point_cloud.npy')\n","P_t_train = np.load('6D_rotated_train_point_cloud.npy')\n","P_t_test = np.load('6D_rotated_test_point_cloud.npy')\n","\n","size = 3000\n","tr_len = 626\n","te_len = 100\n","sbst = tr_len\n","tot = tr_len + te_len\n","out_size = 3\n","\n","#original 3 x 3 matrix, from which we obtain rotor, bivector, euler, and angle axis\n","r = np.load('rotmatr_point_cloud.npy')\n","r = np.reshape(r, [tot, 3, 3])\n","\n","\n","P_r_train = np.reshape(P_r_train, [tr_len,size, 3])\n","P_t_train = np.reshape(P_t_train, [tr_len,size, 3])\n","P_r_test = np.reshape(P_r_test, [te_len,size, 3])\n","P_t_test = np.reshape(P_t_test, [te_len,size, 3])\n","\n","\n","\n","#### adding noise ####\n","'''\n","s = 0.1\n","\n","noise = np.random.normal(0, s, P_t_train.shape)\n","P_t_train = P_t_train + noise\n","noise = np.random.normal(0, s, P_t_train.shape)\n","P_r_train = P_r_train + noise\n","\n","\n","noise = np.random.normal(0, s, P_t_test.shape)\n","P_t_test = P_t_test + noise\n","noise = np.random.normal(0, s, P_t_test.shape)\n","P_r_test = P_r_test + noise\n","\n","\n","'''\n","r = np.reshape(r, [tr_len+te_len, 3* 3])\n","#r = np.reshape(r, [tr_len+te_len, 3, 3])\n","\n","\n","b = []\n","rot = []\n","for i in range(0,tot):\n","    matrix = np.reshape(r[i], [3, 3])\n","\n","    #express the rotation matrix as a quaternion / euler angle / axis angle\n","    Q = R.from_matrix(matrix)\n","    #B = Q.as_euler('xyz')\n","    B = Q.as_rotvec()\n","    #Q = Q.as_quat()\n","\n","    #rotor from quaternion\n","    #Rot = Q[0] + Q[2]*e13 +Q[1]*e23 + Q[3]*e12\n","\n","    #Rot = up(Q[0] + Q[2]*e13 +Q[1]*e23 + Q[3]*e12)\n","\n","    #bivector as exponential\n","    #B = -2*general_logarithm(Rot)\n","\n","    #bivector as Cayley transform\n","    #B = (1 - Rot)/(1 + Rot)\n","\n","\n","    #CGA bivector\n","    '''\n","    rotor = []\n","    for j in range(0,32):\n","        rotor = np.append(rotor, Rot[j])\n","    \n","    rot = np.append(rot, rotor)\n","\n","    B = -2*general_logarithm(Rot)\n","    #B = (1 - Rot)/(1+Rot)\n","    bi = []\n","    for i in range(6,16):\n","        bi = np.append(bi, B[i])\n","\n","    b = np.append(b, bi)\n","    '''\n","    #storing the bivector\n","    b = np.append(b, [B[0], B[1], B[2]]) #for euler / axis angle\n","    #b = np.append(b, [B[6], B[7], B[10]]) #for bivector\n","    #b = np.append(b, [Q[0], Q[2], Q[1], Q[3]]) #for rotor / quaternion\n","\n","\n","#train-test split\n","\n","b = np.reshape(b, [tr_len+te_len, out_size])\n","b_train = b[0:tr_len, :]\n","b_test = b[tr_len:, :]\n","'''\n","\n","r_train = r[0:tr_len, :]\n","r_test = r[tr_len:, :]\n","'''\n","\n","P_r_train = np.reshape(P_r_train, [tr_len, size,3])\n","P_t_train = np.reshape(P_t_train, [tr_len, size,3])\n","\n","tf.executing_eagerly()\n","\n","#defining the deep neural network\n","\n","def MLPNet():\n","    input = Input(shape=(size, 2*3))\n","    x = Conv1D(64, 1)(input)\n","    x = keras.layers.LeakyReLU()(x)\n","    x = Conv1D(128, 1)(x)\n","    x = keras.layers.LeakyReLU()(x)\n","    x = Conv1D(256, 1)(x)\n","    x = keras.layers.LeakyReLU()(x)\n","    x = Conv1D(1024, 1)(x)\n","    out = MaxPooling1D(size)(x)\n","    model = keras.Model(inputs = input, outputs = out)\n","\n","    plot_model(model, show_shapes=True, show_dtype=True)\n","\n","    inp1 = Input(shape=(size,2*3)) \n","    #inp2 = Input(shape=(size,2*3))\n","\n","    model_1 = model(inp1) \n","    #model_2 = model(inp2)\n","    #merge_layers = concatenate([model_1, model_2])\n","    #distance_func = Lambda(lambda t: K.abs(t[0]-t[1]))\n","    #merge_layers = distance_func([model_1, model_2])\n","    #print(merge_layers)\n","\n","    x = Dense(512)(model_1)\n","    x = Dropout(0.5)(x)\n","    x = keras.layers.LeakyReLU()(x)\n","    x = Dense(512)(x)\n","    x = Dropout(0.3)(x)\n","    x = keras.layers.LeakyReLU()(x)\n","    x = Flatten()(x)\n","    fc3 = Dense(out_size)(x)\n","\n","    MLP = keras.Model(inputs=inp1, outputs=[fc3])\n","    plot_model(MLP, show_shapes=True, show_dtype=True)\n","    return MLP\n","    \n","matchnet = MLPNet()\n","matchnet.summary()  #Print Network Structure\n","\n","\n","nb_epoch =  100\n","batch_size = 32\n","\n","#opt = keras.optimizers.SGD(learning_rate=0.0001)\n","\n","import keras.backend as K\n","\n","point = tf.constant([1, 1, 1], tf.float32)\n","\n","def custom_loss(y_true, y_pred):\n","\n","    y_pred = tf.reshape(y_pred, [-1, 3, 3])\n","  \n","    a1 = y_pred[:,:,0]\n","    a2 = y_pred[:,:,1]\n","\n","\n","    b1, _ = tf.linalg.normalize(a1, ord='euclidean')\n","    c = tf.tensordot(b1, a2, axes=[1, 1])\n","    c = a2 - tf.matmul(c, b1)\n","    b2, _ = tf.linalg.normalize(c, ord='euclidean')\n","\n","    b3 = tf.linalg.cross(b1, b2)\n","    y_pred_rot = tf.concat([b1, b2, b3], axis = 1)\n","\n","    l2 = K.mean((y_true - y_pred_rot)**2)\n","\n","    return l2\n","\n","\n","matchnet.compile(loss = 'mae', optimizer = 'adam', run_eagerly=True)\n","\n","P_train = np.concatenate((P_r_train, P_t_train), axis = 2)\n","#P_train = P_r_train - P_t_train\n","es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n","model_train = matchnet.fit(x = P_train, y = b_train, \n","                        validation_split = 0.3,\n","                        epochs=nb_epoch,\n","                        verbose=1,\n","                        shuffle=False,\n","                        callbacks = es_callback,\n","                        batch_size=batch_size)\n","\n","\n","loss = model_train.history['loss']\n","val_loss = model_train.history['val_loss']\n","epochs = range(0,np.size(loss))\n","plt.figure()\n","plt.plot(epochs, loss, 'b-', label='Training loss')\n","plt.plot(epochs, val_loss, 'r-', label='Validation loss')\n","plt.title('Training loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z9c0eFgZ5Fz1"},"source":["# Prediction"]},{"cell_type":"code","metadata":{"id":"D-ZBK1aMiSBw"},"source":["#######PREDICTION FOR ROTOR AND BIVECTOR#######\n","predicted = matchnet.predict(np.concatenate((P_r_test, P_t_test), axis = 2))\n","#predicted = matchnet.predict([P_r_test, P_t_test])\n","\n","TEST = b_test\n","Langle = []\n","\n","\n","for i in range(0,5):\n","    print(predicted[i])\n","    print(TEST[i])\n","    print('----')\n","\n","from math import acos\n","\n","Langle = []\n","'''\n","####BIVECTOR CASE#####\n","for i in range(0, te_len):\n","    B = predicted[i][0]*e12 + predicted[i][1]*e13 + predicted[i][2]*e23\n","    #print(B)\n","    #Cayley transform\n","    Rot_pred = (1-B)/(1+B) \n","    #Exponential\n","    #Rot_pred = e**(-0.5*B)\n","\n","    B = TEST[i][0]*e12 +TEST[i][1]*e13 + TEST[i][2]*e23\n","    #print(B)\n","    #Cayley transform\n","    Rot_real = (1-B)/(1+B) \n","    #Exponential\n","    #Rot_real = e**(-0.5*B)\n","\n","    #print(Rot_pred)\n","    #print(Rot_real)\n","    #print('---')\n","    \n","    cosine = (Rot_real*~Rot_pred)[0]\n","    \n","    if cosine > 1:\n","        cosine = 1\n","    if cosine < -1:\n","        cosine = -1\n","    Langle = np.append(Langle, acos(cosine))\n","\n","\n","print(np.max(Langle)*180/pi)\n","print(np.average(Langle)*180/pi)\n","print(np.std(Langle)*180/pi)\n","\n","\n","'''\n","\n","####ROTOR CASE#####\n","for i in range(0,te_len):\n","    Rot_pred = predicted[i][0] + +predicted[i][1]*e13 + predicted[i][2]*e23 + predicted[i][3]*e12\n","    Rot_real = TEST[i][0] +TEST[i][1]*e13 + TEST[i][2]*e23 + TEST[i][3]*e12\n","\n","    print(Rot_pred)\n","    print(Rot_real)\n","    print('---')\n","    cosine = (Rot_real*~Rot_pred)[0]\n","\n","    if cosine > 1:\n","        cosine = 1\n","    if cosine < -1:\n","        cosine = -1\n","    Langle = np.append(Langle, acos(cosine))\n","\n","print(np.max(Langle)*180/pi)\n","print(np.average(Langle)*180/pi)\n","print(np.std(Langle)*180/pi)\n","\n","#np.save('doublenoise5_bivector_PREDICTED.npy', predicted)\n","#np.save('doublenoise5_b_test.npy', b_test)\n","np.save('rotor_val_loss.npy', val_loss)\n","np.save('rotor_error.npy', Langle)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gsM_oJ_Xz_Vd"},"source":["#######PREDICTION FOR 6D##########\n","\n","predicted = matchnet.predict(np.concatenate((P_r_test, P_t_test), axis = 2))\n","#predicted = matchnet.predict([P_r_test, P_t_test])\n","TEST = r_test\n","\n","Langle = []\n","\n","for i in range(0,int(te_len)):\n","    y_pred = np.reshape(predicted[i], [3, 3])\n","    y_real = np.reshape(r_test[i], [3, 3])\n","    \n","    a1 = y_pred[:,0]\n","    a2 = y_pred[:,1]\n","\n","    b1 = a1 / np.linalg.norm(a1)\n","    b2 = a2 - np.dot(a2,b1)*b1\n","    b2 = b2 / np.linalg.norm(b2)\n","\n","    b3 = np.cross(b1, b2)\n","\n","    #y_pred_n = np.transpose([b1, b2, b3])\n","    y_pred_n = np.reshape([b1, b2, b3], [3,3])\n","    y_real = np.reshape(TEST[i], [3, 3])\n","\n","    \n","    M = np.matmul(y_real, np.linalg.inv(y_pred_n))\n","    cosine = (M[0,0] + M[1,1] + M[2,2] - 1)/2\n","\n","    #M = np.dot(y_real,  1/y_pred)\n","    #cosine = (M - 1)/2\n","    if cosine > 1:\n","        cosine = 1\n","    \n","    if cosine < -1:\n","        cosine = -1\n","    \n","    #if i < 4:\n","        #print(predicted[i])\n","        #print(y_pred)\n","        #print('---')\n","        #print(y_pred_n)\n","        #print(y_pred_n)\n","        #print('---')\n","        #print(y_real)\n","        #print(M)\n","        #print('-----------')\n","    \n","    #print(acos(cosine))\n","    Langle = np.append(Langle, acos(cosine))\n","\n","\n","print(np.max(Langle)*180/pi)\n","print(np.average(Langle)*180/pi)\n","print(np.std(Langle)*180/pi)\n","\n","\n","#np.save('6D_loss.npy', loss)\n","np.save('6D_val_loss.npy', val_loss)\n","np.save('6D_error.npy', Langle)\n","#np.save('doublenoise5_6D_PREDICTED.npy', predicted)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uVbKXrYLosHO"},"source":["#######PREDICTION FOR MATRIX, EULER, ANGLE AXIS##########\n","\n","predicted = matchnet.predict(np.concatenate((P_r_test, P_t_test), axis = 2))\n","#predicted = matchnet.predict([P_r_test, P_t_test])\n","TEST = r_test\n","\n","Langle = []\n","\n","for i in range(0,int(te_len)):\n","    #y_pred = np.reshape(predicted[i], [3, 3])\n","    #y_real = np.reshape(r_test[i], [3, 3])\n","    \n","    y_pred = np.reshape(predicted[i], out_size)\n","    y_real = np.reshape(b_test[i], out_size)\n","\n","    #y_pred = R.from_euler('xyz', y_pred)\n","    y_pred = R.from_rotvec(y_pred)\n","    #y_pred = R.from_quat(y_pred)\n","    y_pred = y_pred.as_matrix()\n","\n","    #y_real = R.from_euler('xyz', y_real)\n","    y_real = R.from_rotvec(y_real)\n","    #y_real = R.from_quat(y_real)\n","    y_real = y_real.as_matrix()\n","    \n","\n","    M = np.matmul(y_real, np.linalg.inv(y_pred))\n","    #print(M)\n","    cosine = (M[0,0] + M[1,1] + M[2,2] - 1)/2\n","\n","    #M = np.dot(y_real,  1/y_pred)\n","    #cosine = (M - 1)/2\n","    if cosine > 1:\n","        cosine = 1\n","    \n","    if cosine < -1:\n","        cosine = -1\n","    \n","    #print(acos(cosine))\n","    Langle = np.append(Langle, acos(cosine))\n","\n","\n","print(np.max(Langle)*180/pi)\n","print(np.average(Langle)*180/pi)\n","print(np.std(Langle)*180/pi)\n","\n","\n","np.save('rotvec_val_loss.npy', val_loss)\n","np.save('rotvec_error.npy', Langle)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WDSc1fn1DWkS"},"source":["#######PREDICTION ON CGA BIVECTOR###############\n","predicted = matchnet.predict(np.concatenate((P_r_test, P_t_test), axis = 2))\n","TEST = b_test\n","from scipy.spatial.transform import Rotation as R\n","Langle = []\n","\n","for i in range(0,int(te_len)):\n","    B = predicted[i][0]*e12 +predicted[i][1]*e13 + predicted[i][2]*e14+ predicted[i][3]*e15 +predicted[i][4]*e23 + predicted[i][5]*e24+predicted[i][6]*e25 +predicted[i][7]*e34 + predicted[i][8]*e35+predicted[i][9]*e45\n","    Rot_pred = e**(-B/5)\n","\n","    #B = predicted[i][0]*e12 +predicted[i][1]*e13 +predicted[i][4]*e23\n","    #Rot_pred = (1-B)/(1+B)       \n","    \n","    #print(Rot_pred)\n","    B = TEST[i][0]*e12 +TEST[i][1]*e13 + TEST[i][2]*e14+ TEST[i][3]*e15+TEST[i][4]*e23 +TEST[i][5]*e24 + TEST[i][6]*e25+ TEST[i][7]*e34+TEST[i][8]*e35 +TEST[i][9]*e45\n","    Rot_real = e**(-B/5)\n","    #Rot_real = (1-B)/(1+B) \n","\n","    \n","\n","    '''\n","    y_pred = [Rot_pred[0], Rot_pred[6], Rot_pred[7], Rot_pred[10]]\n","    y_pred = R.from_quat(y_pred)\n","    y_pred = y_pred.as_matrix()\n","\n","    #y_real = R.from_euler('xyz', y_real)\n","    y_real = [Rot_real[0], Rot_real[6], Rot_real[7], Rot_real[10]]\n","    y_real = R.from_quat(y_real)\n","    y_real = y_real.as_matrix()\n","    \n","    M = np.matmul(y_real, np.linalg.inv(y_pred))\n","    cosine = (M[0,0] + M[1,1] + M[2,2] - 1)/2\n","    '''\n","\n","    cosine = (Rot_real*~Rot_pred)[0]\n","    \n","    #M = np.dot(y_real,  1/y_pred)\n","    #cosine = (M - 1)/2\n","    if cosine > 1:\n","        cosine = 1\n","    \n","    if cosine < -1:\n","        cosine = -1\n","    \n","    #print(acos(cosine))\n","    Langle = np.append(Langle, acos(cosine))\n","\n","    #print(Rot_real)\n","\n","    #print(Rot_real*~Rot_pred)\n","    '''\n","    cosine = (Rot_real*~Rot_pred)[0]\n","    #print(cosine)\n","    print('-----------------')\n","    if cosine > 1:\n","        cosine = 1\n","    Langle = np.append(Langle, acos(cosine))\n","    '''\n","\n","print(np.max(Langle)*180/pi)\n","print(np.average(Langle)*180/pi)\n","print(np.std(Langle)*180/pi)\n","\n","#np.save('airplane_3000_CGAbiv_loss.npy', loss)\n","#np.save('airplane_3000_CGAbiv_val_loss.npy', val_loss)\n","#np.save('airplane_3000_CGAbiv_PREDICTED.npy', predicted)"],"execution_count":null,"outputs":[]}]}