{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning-Bivectors-from-Rotors-5D.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOGMPgAZCqM3g76H85OgapW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertomariapepe/Learning-Rotations/blob/main/Learning_Bivectors_from_Rotors_5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct24ep4CFMo2"
      },
      "source": [
        "!pip install git+https://github.com/pygae/clifford.git@master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL5UJwp3FQZM"
      },
      "source": [
        "!pip install tensorflow_graphics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U4_x4vnJFMFu",
        "outputId": "cbd45fcc-0eb9-4c98-f471-7fdb952f4ebb"
      },
      "source": [
        "from scipy.spatial.transform import Rotation as R\n",
        "import numpy as np\n",
        "from clifford.g3c import *\n",
        "from clifford.tools.g3c import *\n",
        "from clifford.tools.g3c.rotor_parameterisation import *\n",
        "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import acos\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "from math import e, pi\n",
        "import tensorflow_graphics as tfg\n",
        "import tensorflow_graphics.geometry.transformation as tfg_transformation\n",
        "\n",
        "tot = int(1e5)\n",
        "'''\n",
        "#GENERATING THE RANDOM DATASET\n",
        "i = 0\n",
        "\n",
        "rot = []\n",
        "b = []\n",
        "\n",
        "\n",
        "for i in range(0,tot):\n",
        "\n",
        "    R = random_rotation_translation_rotor()\n",
        "\n",
        "    r = []\n",
        "    for i in range(0,32):\n",
        "        r = np.append(r, R[i])\n",
        "    \n",
        "    rot = np.append(rot, r)\n",
        "\n",
        "    B = (1 - R)/(1+R)\n",
        "    bi = []\n",
        "    for i in range(6,16):\n",
        "        bi = np.append(bi, B[i])\n",
        "    \n",
        "    #print(bi)\n",
        "    b = np.append(b, bi)\n",
        "\n",
        "\n",
        "np.save('Bivectors_cayley-5D.npy', b)\n",
        "np.save('Rotors-5D.npy', rot)\n",
        "'''\n",
        "\n",
        "rot = np.load('Rotors-5D.npy')\n",
        "b = np.load('Bivectors_cayley-5D.npy')\n",
        "\n",
        "#rot = np.load('Rotors.npy')\n",
        "#b = np.load('Bivectors_cayley.npy')\n",
        "\n",
        "rot = np.reshape(rot, [tot, 32])\n",
        "b = np.reshape(b, [tot, 10])\n",
        "\n",
        "#Train - Test Split\n",
        "r_train, r_test = train_test_split(rot, test_size=0.33, shuffle=False)\n",
        "b_train, b_test = train_test_split(b, test_size=0.33, shuffle=False)\n",
        "\n",
        "\n",
        "TRAIN = b_train\n",
        "TEST = b_test\n",
        "out_size = 10\n",
        "\n",
        "nb_epoch = 100\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "r_input = Input(shape=(32))\n",
        "x = Dense(128)(r_input)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "x = Dense(128)(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "x = Dense(128)(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "out = Dense(out_size)(x)\n",
        "print(out)\n",
        "\n",
        "\n",
        "model = keras.Model(r_input,  out)\n",
        "model.summary()\n",
        "model.compile(loss='mse', optimizer=\"adam\")\n",
        "#es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "model_train = model.fit(x = r_train, y = TRAIN, \n",
        "                        validation_split=0.3,\n",
        "                        epochs=nb_epoch,\n",
        "                        verbose=1,\n",
        "                        batch_size=batch_size)\n",
        "\n",
        "\n",
        "\n",
        "loss = model_train.history['loss']\n",
        "val_loss = model_train.history['val_loss']\n",
        "epochs = range(nb_epoch)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b-', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "predicted = model.predict(r_test)\n",
        "\n",
        "M = []\n",
        "Langle = []\n",
        "\n",
        "for i in range(0,int(tot*0.33)):\n",
        "    B = predicted[i][0]*e12 +predicted[i][1]*e13 + predicted[i][2]*e14+ predicted[i][3]*e15 +predicted[i][4]*e23 + predicted[i][5]*e24+predicted[i][6]*e25 +predicted[i][7]*e34 + predicted[i][8]*e35+predicted[i][9]*e45\n",
        "    #Rot_pred = e**(-B/2)\n",
        "\n",
        "    Rot_pred = (1-B)/(1+B)       \n",
        "    \n",
        "    #print(Rot_pred)\n",
        "    B = TEST[i][0]*e12 +TEST[i][1]*e13 + TEST[i][2]*e14+ TEST[i][3]*e15+TEST[i][4]*e23 +TEST[i][5]*e24 + TEST[i][6]*e25+ TEST[i][7]*e34+TEST[i][8]*e35 +TEST[i][9]*e45\n",
        "\n",
        "    #Rot_real = e**(-B/2)\n",
        "    Rot_real = (1-B)/(1+B) \n",
        "\n",
        "    #print(Rot_real)\n",
        "\n",
        "    #print(Rot_real*~Rot_pred)\n",
        "    cosine = (Rot_real*~Rot_pred)[0]\n",
        "    #print(cosine)\n",
        "    #print('-----------------')\n",
        "    if cosine > 1:\n",
        "        cosine = 1\n",
        "    Langle = np.append(Langle, acos(cosine))\n",
        "    if (acos(cosine)*180/pi) > 90:\n",
        "        print(acos(cosine)*180/pi)\n",
        "\n",
        "\n",
        "print(np.max(Langle)*180/pi)\n",
        "print(np.average(Langle)*180/pi)\n",
        "print(np.std(Langle)*180/pi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='dense_27/BiasAdd:0', description=\"created by layer 'dense_27'\")\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Total params: 38,538\n",
            "Trainable params: 38,538\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "733/733 [==============================] - 3s 3ms/step - loss: 0.9941 - val_loss: 0.1348\n",
            "Epoch 2/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.1000 - val_loss: 0.0341\n",
            "Epoch 3/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0321 - val_loss: 0.0185\n",
            "Epoch 4/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0220 - val_loss: 0.0146\n",
            "Epoch 5/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0158 - val_loss: 0.0119\n",
            "Epoch 6/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0132 - val_loss: 0.0132\n",
            "Epoch 7/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0127 - val_loss: 0.0120\n",
            "Epoch 8/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0132 - val_loss: 0.0112\n",
            "Epoch 9/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0124 - val_loss: 0.0115\n",
            "Epoch 10/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0124 - val_loss: 0.0079\n",
            "Epoch 11/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0092 - val_loss: 0.0251\n",
            "Epoch 12/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0127 - val_loss: 0.0266\n",
            "Epoch 13/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0114 - val_loss: 0.0088\n",
            "Epoch 14/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0083 - val_loss: 0.0181\n",
            "Epoch 15/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0096 - val_loss: 0.0073\n",
            "Epoch 16/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0086 - val_loss: 0.0090\n",
            "Epoch 17/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0091 - val_loss: 0.0060\n",
            "Epoch 18/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0081 - val_loss: 0.0099\n",
            "Epoch 19/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0074 - val_loss: 0.0052\n",
            "Epoch 20/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0075 - val_loss: 0.0061\n",
            "Epoch 21/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0084 - val_loss: 0.0071\n",
            "Epoch 22/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0076 - val_loss: 0.0060\n",
            "Epoch 23/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0070 - val_loss: 0.0073\n",
            "Epoch 24/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0070 - val_loss: 0.0183\n",
            "Epoch 25/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0076 - val_loss: 0.0088\n",
            "Epoch 26/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0075 - val_loss: 0.0092\n",
            "Epoch 27/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0074 - val_loss: 0.0056\n",
            "Epoch 28/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0068 - val_loss: 0.0074\n",
            "Epoch 29/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0067 - val_loss: 0.0068\n",
            "Epoch 30/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0068 - val_loss: 0.0065\n",
            "Epoch 31/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0050 - val_loss: 0.0062\n",
            "Epoch 32/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0062 - val_loss: 0.0045\n",
            "Epoch 33/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0046 - val_loss: 0.0075\n",
            "Epoch 34/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0073 - val_loss: 0.0044\n",
            "Epoch 35/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0052 - val_loss: 0.0071\n",
            "Epoch 36/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0067 - val_loss: 0.0063\n",
            "Epoch 37/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0059 - val_loss: 0.0047\n",
            "Epoch 38/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0050 - val_loss: 0.0052\n",
            "Epoch 39/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0064 - val_loss: 0.0058\n",
            "Epoch 40/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0056 - val_loss: 0.0055\n",
            "Epoch 41/100\n",
            "733/733 [==============================] - 3s 3ms/step - loss: 0.0059 - val_loss: 0.0044\n",
            "Epoch 42/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0052 - val_loss: 0.0041\n",
            "Epoch 43/100\n",
            "733/733 [==============================] - 3s 4ms/step - loss: 0.0049 - val_loss: 0.0058\n",
            "Epoch 44/100\n",
            "733/733 [==============================] - 3s 3ms/step - loss: 0.0056 - val_loss: 0.0240\n",
            "Epoch 45/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0068 - val_loss: 0.0037\n",
            "Epoch 46/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0060 - val_loss: 0.0042\n",
            "Epoch 47/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0046 - val_loss: 0.0041\n",
            "Epoch 48/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0042 - val_loss: 0.0051\n",
            "Epoch 49/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0048 - val_loss: 0.0070\n",
            "Epoch 50/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0043 - val_loss: 0.0071\n",
            "Epoch 51/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0051 - val_loss: 0.0040\n",
            "Epoch 52/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0052 - val_loss: 0.0046\n",
            "Epoch 53/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0050 - val_loss: 0.0056\n",
            "Epoch 54/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0047 - val_loss: 0.0071\n",
            "Epoch 55/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0046 - val_loss: 0.0055\n",
            "Epoch 56/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0055 - val_loss: 0.0041\n",
            "Epoch 57/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0041 - val_loss: 0.0096\n",
            "Epoch 58/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0050 - val_loss: 0.0057\n",
            "Epoch 59/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0041 - val_loss: 0.0080\n",
            "Epoch 60/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0052 - val_loss: 0.0044\n",
            "Epoch 61/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0038 - val_loss: 0.0050\n",
            "Epoch 62/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0043 - val_loss: 0.0040\n",
            "Epoch 63/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0038 - val_loss: 0.0059\n",
            "Epoch 64/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0045 - val_loss: 0.0034\n",
            "Epoch 65/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0035 - val_loss: 0.0124\n",
            "Epoch 66/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0052 - val_loss: 0.0044\n",
            "Epoch 67/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0040 - val_loss: 0.0056\n",
            "Epoch 68/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0044 - val_loss: 0.0052\n",
            "Epoch 69/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0056 - val_loss: 0.0082\n",
            "Epoch 70/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0042 - val_loss: 0.0038\n",
            "Epoch 71/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 72/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0053 - val_loss: 0.0033\n",
            "Epoch 73/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0033 - val_loss: 0.0033\n",
            "Epoch 74/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0036 - val_loss: 0.0027\n",
            "Epoch 75/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0037 - val_loss: 0.0058\n",
            "Epoch 76/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0032 - val_loss: 0.0088\n",
            "Epoch 77/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0053 - val_loss: 0.0049\n",
            "Epoch 78/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0049 - val_loss: 0.0035\n",
            "Epoch 79/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0034 - val_loss: 0.0048\n",
            "Epoch 80/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0047 - val_loss: 0.0039\n",
            "Epoch 81/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0038 - val_loss: 0.0040\n",
            "Epoch 82/100\n",
            "733/733 [==============================] - 3s 4ms/step - loss: 0.0044 - val_loss: 0.0031\n",
            "Epoch 83/100\n",
            "733/733 [==============================] - 3s 3ms/step - loss: 0.0031 - val_loss: 0.0051\n",
            "Epoch 84/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0034 - val_loss: 0.0064\n",
            "Epoch 85/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0042 - val_loss: 0.0035\n",
            "Epoch 86/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0039 - val_loss: 0.0033\n",
            "Epoch 87/100\n",
            "733/733 [==============================] - 3s 3ms/step - loss: 0.0035 - val_loss: 0.0026\n",
            "Epoch 88/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0040 - val_loss: 0.0038\n",
            "Epoch 89/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0041 - val_loss: 0.0054\n",
            "Epoch 90/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 91/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0031 - val_loss: 0.0055\n",
            "Epoch 92/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0052 - val_loss: 0.0051\n",
            "Epoch 93/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0034 - val_loss: 0.0037\n",
            "Epoch 94/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0038 - val_loss: 0.0050\n",
            "Epoch 95/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0037 - val_loss: 0.0022\n",
            "Epoch 96/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0032 - val_loss: 0.0047\n",
            "Epoch 97/100\n",
            "733/733 [==============================] - 3s 3ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 98/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0033 - val_loss: 0.0061\n",
            "Epoch 99/100\n",
            "733/733 [==============================] - 2s 3ms/step - loss: 0.0036 - val_loss: 0.0038\n",
            "Epoch 100/100\n",
            "733/733 [==============================] - 3s 3ms/step - loss: 0.0039 - val_loss: 0.0090\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: DeprecationWarning: Treating MultiVector objects like a sequence is deprecated. To access the coefficients as a sequence, use the `.value` attribute.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "54.618562344033315\n",
            "3.9913347130932055\n",
            "2.5157341478309942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfuDnzIUIBsN",
        "outputId": "467b7643-6870-4961-9a14-d9f2f2803317"
      },
      "source": [
        "M = []\n",
        "Langle = []\n",
        "\n",
        "for i in range(0,int(tot*0.33)):\n",
        "    B = predicted[i][0]*e12 +predicted[i][1]*e13 + predicted[i][2]*e14+ predicted[i][3]*e15 +predicted[i][4]*e23 + predicted[i][5]*e24+predicted[i][6]*e25 +predicted[i][7]*e34 + predicted[i][8]*e35+predicted[i][9]*e45\n",
        "    #Rot_pred = e**(-B/2)\n",
        "\n",
        "    Rot_pred = (1-B)/(1+B)       \n",
        "    \n",
        "    #print(Rot_pred)\n",
        "    B = TEST[i][0]*e12 +TEST[i][1]*e13 + TEST[i][2]*e14+ TEST[i][3]*e15+TEST[i][4]*e23 +TEST[i][5]*e24 + TEST[i][6]*e25+ TEST[i][7]*e34+TEST[i][8]*e35 +TEST[i][9]*e45\n",
        "\n",
        "    #Rot_real = e**(-B/2)\n",
        "    Rot_real = (1-B)/(1+B) \n",
        "\n",
        "    #print(Rot_real)\n",
        "\n",
        "    #print(Rot_real*~Rot_pred)\n",
        "    cosine = (Rot_real*~Rot_pred)[0]\n",
        "    #print(cosine)\n",
        "    #print('-----------------')\n",
        "    if cosine > 1:\n",
        "        cosine = 1\n",
        "    Langle = np.append(Langle, acos(cosine))\n",
        "    if (acos(cosine)*180/pi) > 90:\n",
        "        print(acos(cosine)*180/pi)\n",
        "\n",
        "\n",
        "print(np.max(Langle)*180/pi)\n",
        "print(np.average(Langle)*180/pi)\n",
        "print(np.std(Langle)*180/pi)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: Treating MultiVector objects like a sequence is deprecated. To access the coefficients as a sequence, use the `.value` attribute.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "69.60563022930515\n",
            "3.1016152592149475\n",
            "4.214392054768325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5PGLEfxEOw1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}